import crypto from "crypto";
import { getOpenAIClient } from "./openai";
import { getQdrantClient, ensureCollection } from "./qdrant";
import { TextChunk } from "./chunking";
import { AudioMetadata, GenericMetadata } from "./metadata";

export interface ChunkWithEmbedding extends TextChunk {
  embedding: number[];
  metadata: {
    jobId: string;
    userId: string;
    modality: string;
    chunkIndex: number;
    keywords: string[];
    speakers?: string[];
    summary?: string;
    topics?: string[];
    sourceName?: string;
    sourceDate?: string; // ISO date string from source (e.g., meeting date, article publish date)
    processedAt: string; // ISO date string when chunk was processed
  };
}

export async function createEmbeddingsAndStore(
  chunks: TextChunk[],
  jobId: string,
  userId: string,
  modality: string,
  metadata: AudioMetadata | GenericMetadata,
  sourceName?: string,
  sourceDate?: Date, // Optional source date (e.g., meeting date, article publish date)
): Promise<number> {
  console.log(`   üìä Total chunks to process: ${chunks.length}`);
  console.log(`   üóÑÔ∏è  Qdrant collection: twinmind_${userId}`);
  console.log(`   ü§ñ Embedding model: text-embedding-3-small`);
  console.log(`   üì¶ Batch size: 10 chunks`);

  const openai = getOpenAIClient();
  const collectionName = `twinmind_${userId}`;

  // Ensure collection exists
  console.log(`   üîç Ensuring Qdrant collection exists...`);
  await ensureCollection(collectionName);
  console.log(`   ‚úÖ Collection ready`);

  const qdrant = getQdrantClient();

  let storedCount = 0;

  // Process chunks in batches to avoid rate limits
  const batchSize = 10;
  const totalBatches = Math.ceil(chunks.length / batchSize);
  
  for (let i = 0; i < chunks.length; i += batchSize) {
    const batch = chunks.slice(i, i + batchSize);
    const batchNum = Math.floor(i / batchSize) + 1;
    
    console.log(`   üì¶ Processing batch ${batchNum}/${totalBatches} (${batch.length} chunks)...`);

    // Create embeddings for batch
    const texts = batch.map((chunk) => chunk.text);
    console.log(`      ü§ñ Calling OpenAI embeddings API...`);
    const embeddingResponse = await openai.embeddings.create({
      model: "text-embedding-3-small",
      input: texts,
    });
    console.log(`      ‚úÖ Received ${embeddingResponse.data.length} embeddings`);

    // Store each chunk with its embedding
    // Qdrant requires point IDs to be UUIDs (strings) or integers
    // Using a hash-based approach to create unique integer IDs
    const points = batch.map((chunk, idx) => {
      const embedding = embeddingResponse.data[idx].embedding;
      // Create a deterministic integer ID from jobId and chunk index
      // Hash the combination and convert to a positive integer
      const pointIdString = `${jobId}_chunk_${i + idx}`;
      const hash = crypto.createHash("sha256").update(pointIdString).digest("hex");
      // Convert first 15 hex chars to integer (safe for JavaScript numbers)
      const pointId = parseInt(hash.substring(0, 15), 16);

      const now = new Date().toISOString();
      return {
        id: pointId,
        vector: embedding,
        payload: {
          text: chunk.text,
          jobId,
          userId,
          modality,
          chunkIndex: i + idx,
          tokenCount: chunk.tokenCount,
          keywords: metadata.keywords || [],
          speakers: (metadata as AudioMetadata).speakers || [],
          speaker: chunk.speaker || null, // Primary speaker for this chunk
          chunkSpeakers: chunk.speakers || [], // All speakers in this chunk
          summary: metadata.summary,
          topics: metadata.topics || [],
          sourceName: sourceName || null,
          createdAt: now, // When chunk was created/processed
          processedAt: now, // When chunk was processed
          sourceDate: sourceDate ? sourceDate.toISOString() : null, // Original source date (e.g., meeting date)
        },
      };
    });

    console.log(`      üíæ Storing ${points.length} points in Qdrant...`);
    console.log(`      üìã Sample point ID: ${points[0]?.id}`);
    console.log(`      üìã Sample vector size: ${points[0]?.vector?.length || 0}`);
    
    try {
      await qdrant.upsert(collectionName, {
        wait: true,
        points,
      });
    } catch (error: any) {
      console.error(`      ‚ùå Qdrant upsert error details:`);
      console.error(`         Status: ${error.status || "unknown"}`);
      console.error(`         Message: ${error.message || "unknown"}`);
      if (error.data) {
        console.error(`         Error data:`, JSON.stringify(error.data, null, 2));
      }
      if (error.response?.data) {
        console.error(`         Response data:`, JSON.stringify(error.response.data, null, 2));
      }
      throw error;
    }

    storedCount += batch.length;
    console.log(`      ‚úÖ Batch ${batchNum} complete: ${storedCount}/${chunks.length} chunks stored`);
  }

  console.log(`   üéâ All ${storedCount} chunks successfully stored in Qdrant`);
  return storedCount;
}

